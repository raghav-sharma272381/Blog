{"title":"How convolution neural networks work and why are they so efficient ?","markdown":{"yaml":{"title":" How convolution neural networks work and why are they so efficient ?","author":"Raghav Sharma","date":"2025-03-15","categories":["Machine learning","Convolution Neural Networks"],"image":"image.png","highlight-style":"github","engine":"markdown"},"headingText":"How Convolutions Work","containsRefs":false,"markdown":"\n\nI was trying to create a MNIST classification model using CNNs and NNs in PyTorch and was surprised when I looked at the difference in number of parameters between similar performing CNN and a simple NN. \n\nThis Multi-layered neural network had an accuracy of around 97%.\n\n```python\nmodel = nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))\n```\nand it used around **39,700** parameters (weights) to do that. \n\nThis CNN also had an accuracy of around 97%. \n\n```python\ndef conv(ni, nf, ks=3, stride=2, act=True):\n    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res\n\nsimple_cnn = nn.Sequential(\n    conv(1 ,4),            #14x14\n    conv(4 ,8),            #7x7\n    conv(8 ,16),           #4x4\n    conv(16,16),           #2x2\n    conv(16,10, act=False), #1x1\n    nn.Flatten(),\n)\n```\nand it only used around **5,274** parameters (weights) to do that. \n\nWhat are the reasons behind this stark difference in number of parameters? This led me to an investigative journey which deepened my understanding of how CNNs work, but before understanding CNNs, I am expecting that you understand how Neural Networks work. \n\n\nA Convolution is like a sliding window over the data. It can be any data with a grid-like structure. It can be a time-series data which is a 1D grid or image data like in our case which can be viewed as a 2D grid. \n\n<img alt=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding\" width=\"774\" caption=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"three_by_five_conv\" src=\"att_00030.png\">\n\n\nHere we have a Kernel of 3x3 (black box), which is sliding over an image of size 5x5 with padding 1 and stride of 2 (sliding 2 pixels at a time) which creates an activation map of 3x3. This is how Convolutions happen in our CNN. \n\n## How CNNs Work\n\nFor a simple neural net, we matrix multiply the input with the Parameters (weights). This means that each and every input unit interacts with each and every weight exactly once for calculating the output of a layer, which makes a Traditional neural net different from a Convolutional Neural Network.\n\n$$\nW =\n\\begin{bmatrix}\nw_1 & w_2 & w_3 \\\\\nw_4 & w_5 & w_6 \\\\\nw_7 & w_8 & w_9\n\\end{bmatrix}\n$$\n\n\n$$\nX =\n\\begin{bmatrix}\nx_1 & x_2 & x_3 \\\\\nx_4 & x_5 & x_6 \\\\\nx_7 & x_8 & x_9\n\\end{bmatrix}\n$$\n\n\n$$\nX@W =\n\\begin{bmatrix}\n(x_1 w_1 + x_2 w_4 + x_3 w_7) & (x_1 w_2 + x_2 w_5 + x_3 w_8) & (x_1 w_3 + x_2 w_6 + x_3 w_9) \\\\\n(x_4 w_1 + x_5 w_4 + x_6 w_7) & (x_4 w_2 + x_5 w_5 + x_6 w_8) & (x_4 w_3 + x_5 w_6 + x_6 w_9) \\\\\n(x_7 w_1 + x_8 w_4 + x_9 w_7) & (x_7 w_2 + x_8 w_5 + x_9 w_8) & (x_7 w_3 + x_8 w_6 + x_9 w_9)\n\\end{bmatrix}\n$$\n\nIf we had to represent a 2x2 kernel sliding over a 3x3 input in a matrix form, it would look something like below, and it will create an activation map which is 4x4. If you look and compare the two operations, you can see that there are two main differences:\n\n1. Weights are Repeating\n2. Weight matrix for CNNs is filled with zeros \n\n$$\nW = \n\\begin{bmatrix}\nk_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 & 0 \\\\\n0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 \\\\\n0 & 0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4\n\\end{bmatrix}\n$$\n$$\nX=\n\\begin{bmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6 \\\\ x_7 \\\\ x_8 \\\\ x_9\n\\end{bmatrix}\n$$\n\n$$\nX@W =\n\\begin{bmatrix}\nk_1 x_1 + k_2 x_2 + k_3 x_4 + k_4 x_5 \\\\\nk_1 x_2 + k_2 x_3 + k_3 x_5 + k_4 x_6 \\\\\nk_1 x_4 + k_2 x_5 + k_3 x_7 + k_4 x_8 \\\\\nk_1 x_5 + k_2 x_6 + k_3 x_8 + k_4 x_9\n\\end{bmatrix}\n$$\n\nLet's explore these differences further. \n\n**Repeating Weights (parameter sharing)** - It is one of the reasons behind the efficiency of CNNs. In Dense matrix multiplication, input gets multiplied with a parameter exactly once to create an output, which is not the case in Convolutional Neural Networks. The kernel slides over the input, which means that each parameter of the kernel is used at every position in the input. Therefore, rather than learning different parameters for every position, we only learn one set of weights. \n\n**Weight Matrix filled with zeros (sparse representation)** - The size of the kernel is smaller than the size of the input. Therefore, when we represent the convolutions in a matrix multiplication operation, it results in a matrix which is filled with zeros. One might think that because of all these zeros we might be losing some features of the input, especially in strided convolutions, which is not optimal. But if we look at the diagram below, you can see that is not the case. With X being our input, h being a shallow layer, and g being a deep layer, you can see that the deeper layer is connected to almost all of the image's features. \n\n<img alt=\"diagram for sparse connection taken from Deep Learning book by Ian Goodfellow\" width=\"774\" caption=\"diagram for sparse connection taken from Deep Learning book by Ian Goodfellow\" id=\"sparceconnection\" src=\"sparceconectivity.png\">\n\n## Understanding the Code \n\nSo what does it mean when we are writing this code? \n\n```python\nconv(1, 4)\n```\n\nThis function will receive a 28x28 image (ignoring batch_size) with one channel (since it's black and white) and the output of this layer after using ReLU will be 4 different activation maps created by 4 different kernels. The size of the activation maps will be 14x14 (because of stride=2), and the same happens till the last layer which outputs the probability distribution for each digit from 0-9. We are not using ReLU in the last layer as we are using cross_entropy loss function which has its own softmax function and expects raw logits. \n\nThis layer has 1 input channel, 4 output channels, and a 3×3 kernel. Therefore, the total parameters of this layer will be:\n\n```\n1×4×3×3 = 36 parameters \n```\n\nConfirming our calculations by fetching the parameters of the first layer:\n\n```python\nconv1 = simple_cnn[0][0]\nconv1.weight\n```\n\n```\nParameter containing:\ntensor([[[[ 0.2922,  0.3600,  0.2967],\n          [-0.0044,  0.0414, -0.0608],\n          [ 0.1634, -0.0885,  0.2995]]],\n\n\n        [[[-0.2102,  0.3089, -0.1890],\n          [-0.1660,  0.1155,  0.3302],\n          [-0.0576,  0.0286, -0.2662]]],\n\n\n        [[[-0.3527, -0.0673,  0.2557],\n          [-0.1725, -0.3262, -0.3382],\n          [-0.1993, -0.3218, -0.5433]]],\n\n\n        [[[ 0.3354,  0.4143,  0.6307],\n          [ 0.8166,  1.2680,  0.7831],\n          [ 0.5499,  1.0570,  1.0479]]]], device='cuda:0', requires_grad=True)\n```\n\nAs you can see, the first layer has 36 parameters, just as we calculated. Each 3x3 matrix that you can see in the output is a kernel containing different parameters which will slide over our input image. \n\n\n### References\n\nFast.ai Course\nHoward, J. (n.d.). Lesson 15: Deep learning for coders. Fast.ai. Retrieved March 15, 2025, from https://course.fast.ai/Lessons/lesson15.html\n\nDeep Learning Book\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Convolutional networks. In Deep learning (pp. 326-366). MIT Press. https://www.deeplearningbook.org/contents/convnets.html\n\nMedium Article\nBasart, J. (2018, July 9). CNNs from different viewpoints. Medium - Impact AI. https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c\n","srcMarkdownNoYaml":"\n\nI was trying to create a MNIST classification model using CNNs and NNs in PyTorch and was surprised when I looked at the difference in number of parameters between similar performing CNN and a simple NN. \n\nThis Multi-layered neural network had an accuracy of around 97%.\n\n```python\nmodel = nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))\n```\nand it used around **39,700** parameters (weights) to do that. \n\nThis CNN also had an accuracy of around 97%. \n\n```python\ndef conv(ni, nf, ks=3, stride=2, act=True):\n    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res\n\nsimple_cnn = nn.Sequential(\n    conv(1 ,4),            #14x14\n    conv(4 ,8),            #7x7\n    conv(8 ,16),           #4x4\n    conv(16,16),           #2x2\n    conv(16,10, act=False), #1x1\n    nn.Flatten(),\n)\n```\nand it only used around **5,274** parameters (weights) to do that. \n\nWhat are the reasons behind this stark difference in number of parameters? This led me to an investigative journey which deepened my understanding of how CNNs work, but before understanding CNNs, I am expecting that you understand how Neural Networks work. \n\n## How Convolutions Work\n\nA Convolution is like a sliding window over the data. It can be any data with a grid-like structure. It can be a time-series data which is a 1D grid or image data like in our case which can be viewed as a 2D grid. \n\n<img alt=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding\" width=\"774\" caption=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"three_by_five_conv\" src=\"att_00030.png\">\n\n\nHere we have a Kernel of 3x3 (black box), which is sliding over an image of size 5x5 with padding 1 and stride of 2 (sliding 2 pixels at a time) which creates an activation map of 3x3. This is how Convolutions happen in our CNN. \n\n## How CNNs Work\n\nFor a simple neural net, we matrix multiply the input with the Parameters (weights). This means that each and every input unit interacts with each and every weight exactly once for calculating the output of a layer, which makes a Traditional neural net different from a Convolutional Neural Network.\n\n$$\nW =\n\\begin{bmatrix}\nw_1 & w_2 & w_3 \\\\\nw_4 & w_5 & w_6 \\\\\nw_7 & w_8 & w_9\n\\end{bmatrix}\n$$\n\n\n$$\nX =\n\\begin{bmatrix}\nx_1 & x_2 & x_3 \\\\\nx_4 & x_5 & x_6 \\\\\nx_7 & x_8 & x_9\n\\end{bmatrix}\n$$\n\n\n$$\nX@W =\n\\begin{bmatrix}\n(x_1 w_1 + x_2 w_4 + x_3 w_7) & (x_1 w_2 + x_2 w_5 + x_3 w_8) & (x_1 w_3 + x_2 w_6 + x_3 w_9) \\\\\n(x_4 w_1 + x_5 w_4 + x_6 w_7) & (x_4 w_2 + x_5 w_5 + x_6 w_8) & (x_4 w_3 + x_5 w_6 + x_6 w_9) \\\\\n(x_7 w_1 + x_8 w_4 + x_9 w_7) & (x_7 w_2 + x_8 w_5 + x_9 w_8) & (x_7 w_3 + x_8 w_6 + x_9 w_9)\n\\end{bmatrix}\n$$\n\nIf we had to represent a 2x2 kernel sliding over a 3x3 input in a matrix form, it would look something like below, and it will create an activation map which is 4x4. If you look and compare the two operations, you can see that there are two main differences:\n\n1. Weights are Repeating\n2. Weight matrix for CNNs is filled with zeros \n\n$$\nW = \n\\begin{bmatrix}\nk_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 & 0 \\\\\n0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 \\\\\n0 & 0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4\n\\end{bmatrix}\n$$\n$$\nX=\n\\begin{bmatrix}\nx_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6 \\\\ x_7 \\\\ x_8 \\\\ x_9\n\\end{bmatrix}\n$$\n\n$$\nX@W =\n\\begin{bmatrix}\nk_1 x_1 + k_2 x_2 + k_3 x_4 + k_4 x_5 \\\\\nk_1 x_2 + k_2 x_3 + k_3 x_5 + k_4 x_6 \\\\\nk_1 x_4 + k_2 x_5 + k_3 x_7 + k_4 x_8 \\\\\nk_1 x_5 + k_2 x_6 + k_3 x_8 + k_4 x_9\n\\end{bmatrix}\n$$\n\nLet's explore these differences further. \n\n**Repeating Weights (parameter sharing)** - It is one of the reasons behind the efficiency of CNNs. In Dense matrix multiplication, input gets multiplied with a parameter exactly once to create an output, which is not the case in Convolutional Neural Networks. The kernel slides over the input, which means that each parameter of the kernel is used at every position in the input. Therefore, rather than learning different parameters for every position, we only learn one set of weights. \n\n**Weight Matrix filled with zeros (sparse representation)** - The size of the kernel is smaller than the size of the input. Therefore, when we represent the convolutions in a matrix multiplication operation, it results in a matrix which is filled with zeros. One might think that because of all these zeros we might be losing some features of the input, especially in strided convolutions, which is not optimal. But if we look at the diagram below, you can see that is not the case. With X being our input, h being a shallow layer, and g being a deep layer, you can see that the deeper layer is connected to almost all of the image's features. \n\n<img alt=\"diagram for sparse connection taken from Deep Learning book by Ian Goodfellow\" width=\"774\" caption=\"diagram for sparse connection taken from Deep Learning book by Ian Goodfellow\" id=\"sparceconnection\" src=\"sparceconectivity.png\">\n\n## Understanding the Code \n\nSo what does it mean when we are writing this code? \n\n```python\nconv(1, 4)\n```\n\nThis function will receive a 28x28 image (ignoring batch_size) with one channel (since it's black and white) and the output of this layer after using ReLU will be 4 different activation maps created by 4 different kernels. The size of the activation maps will be 14x14 (because of stride=2), and the same happens till the last layer which outputs the probability distribution for each digit from 0-9. We are not using ReLU in the last layer as we are using cross_entropy loss function which has its own softmax function and expects raw logits. \n\nThis layer has 1 input channel, 4 output channels, and a 3×3 kernel. Therefore, the total parameters of this layer will be:\n\n```\n1×4×3×3 = 36 parameters \n```\n\nConfirming our calculations by fetching the parameters of the first layer:\n\n```python\nconv1 = simple_cnn[0][0]\nconv1.weight\n```\n\n```\nParameter containing:\ntensor([[[[ 0.2922,  0.3600,  0.2967],\n          [-0.0044,  0.0414, -0.0608],\n          [ 0.1634, -0.0885,  0.2995]]],\n\n\n        [[[-0.2102,  0.3089, -0.1890],\n          [-0.1660,  0.1155,  0.3302],\n          [-0.0576,  0.0286, -0.2662]]],\n\n\n        [[[-0.3527, -0.0673,  0.2557],\n          [-0.1725, -0.3262, -0.3382],\n          [-0.1993, -0.3218, -0.5433]]],\n\n\n        [[[ 0.3354,  0.4143,  0.6307],\n          [ 0.8166,  1.2680,  0.7831],\n          [ 0.5499,  1.0570,  1.0479]]]], device='cuda:0', requires_grad=True)\n```\n\nAs you can see, the first layer has 36 parameters, just as we calculated. Each 3x3 matrix that you can see in the output is a kernel containing different parameters which will slide over our input image. \n\n\n### References\n\nFast.ai Course\nHoward, J. (n.d.). Lesson 15: Deep learning for coders. Fast.ai. Retrieved March 15, 2025, from https://course.fast.ai/Lessons/lesson15.html\n\nDeep Learning Book\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Convolutional networks. In Deep learning (pp. 326-366). MIT Press. https://www.deeplearningbook.org/contents/convnets.html\n\nMedium Article\nBasart, J. (2018, July 9). CNNs from different viewpoints. Medium - Impact AI. https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"highlight-style":"github","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.40","theme":["cosmo","brand"],"title-block-banner":true,"title":" How convolution neural networks work and why are they so efficient ?","author":"Raghav Sharma","date":"2025-03-15","categories":["Machine learning","Convolution Neural Networks"],"image":"image.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}