{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Post With Code\"\n",
        "author: \"Harlow Malloc\"\n",
        "date: \"2025-02-15\"\n",
        "categories: [news, code, analysis]\n",
        "image: \"image.jpg\"\n",
        "---\n",
        "\n",
        "\n",
        "# How convolution neural networks work and why are they so efficient ?\n",
        "\n",
        "I was trying to create a MNIST classification model using CNNs and NNs in pytorch and was surprised when I looked at the difference in number of parameters between similar performing CNN and a simple NN. \n",
        "\n",
        "This Multi-layerd neural network, had an accuracy of around 97%.\n"
      ],
      "id": "f5312f5e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = nn.Sequential(nn.Linear(784,50), nn.ReLU(), nn.Linear(50,10))"
      ],
      "id": "48aed450",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and it used around **39,700** parameters(weights) to do that. \n",
        "\n",
        "This CNN also had an accuracy of around 97%. \n"
      ],
      "id": "2dfcbf14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def conv(ni, nf, ks=3, stride=2, act=True):\n",
        "    res = nn.Conv2d(ni, nf, stride=stride, kernel_size=ks, padding=ks//2)\n",
        "    if act: res = nn.Sequential(res, nn.ReLU())\n",
        "    return res\n",
        "\n",
        "simple_cnn = nn.Sequential(\n",
        "    conv(1 ,4),            #14x14\n",
        "    conv(4 ,8),            #7x7\n",
        "    conv(8 ,16),           #4x4\n",
        "    conv(16,16),           #2x2\n",
        "    conv(16,10, act=False), #1x1\n",
        "    nn.Flatten(),\n",
        ")"
      ],
      "id": "4af30681",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and it only used around **5,274** parameters(weights) to do that. \n",
        "\n",
        "What are the reasons behind this stark difference in number of parameters this led me to a investigative journey which deepend my understand of how CNN works, but before understanding CNN I am expecting that you understand how Neural networks. \n",
        "\n",
        "## How Convolutions work\n",
        "\n",
        "A Convolution is like a sliding window over the data, it can be any data with grid like structure, It can be a time-series data which is a 1D grid or image data like in our case which can be viewed as a 2D grid. \n",
        "\n",
        "<img alt=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding\" width=\"774\" caption=\"A 3×3 kernel with 5×5 input, stride-2 convolution, and 1 pixel of padding (courtesy of Vincent Dumoulin and Francesco Visin)\" id=\"three_by_five_conv\" src=\"att_00030.png\">\n",
        "\n",
        "\n",
        "Here we have a Kernal of 3x3(black box), which is sliding over an image of size 5x5 with padding 1 and stride of 2(sliding 2 pixels at time) which creates an activation map of 3X3. This is how Convolutions happens in our CNN. \n",
        "\n",
        "## How CNNs Work\n",
        "\n",
        "For a simple neural net we matrix multiply the input with the Parameters(weights). This means that each and every input unit interacts with each and every weight exactly once for calcualting output of a layer, Which makes a Traditional neural net different from a Convolution Neural network.\n",
        "\n",
        "$$\n",
        "W =\n",
        "\\begin{bmatrix}\n",
        "w_1 & w_2 & w_3 \\\\\n",
        "w_4 & w_5 & w_6 \\\\\n",
        "w_7 & w_8 & w_9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "X =\n",
        "\\begin{bmatrix}\n",
        "x_1 & x_2 & x_3 \\\\\n",
        "x_4 & x_5 & x_6 \\\\\n",
        "x_7 & x_8 & x_9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "X@W =\n",
        "\\begin{bmatrix}\n",
        "(x_1 w_1 + x_2 w_4 + x_3 w_7) & (x_1 w_2 + x_2 w_5 + x_3 w_8) & (x_1 w_3 + x_2 w_6 + x_3 w_9) \\\\\n",
        "(x_4 w_1 + x_5 w_4 + x_6 w_7) & (x_4 w_2 + x_5 w_5 + x_6 w_8) & (x_4 w_3 + x_5 w_6 + x_6 w_9) \\\\\n",
        "(x_7 w_1 + x_8 w_4 + x_9 w_7) & (x_7 w_2 + x_8 w_5 + x_9 w_8) & (x_7 w_3 + x_8 w_6 + x_9 w_9)\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "If we had to repersent a 2x2 kernal sliding over a 3x3 input in a matrix form it would look something like below, and it will create a activation map which is 4x4. If you look and comapre the 2 operations you can see that there are 2 main differences.\n",
        "\n",
        "1. Weights are Repeating\n",
        "2. Weight matrix for CNNs is filled with zeros \n",
        "\n",
        "$$\n",
        "W = \n",
        "\\begin{bmatrix}\n",
        "k_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 & 0 \\\\\n",
        "0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 & 0 & 0 \\\\\n",
        "0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4 & 0 \\\\\n",
        "0 & 0 & 0 & 0 & k_1 & k_2 & 0 & k_3 & k_4\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "$$\n",
        "X=\n",
        "\\begin{bmatrix}\n",
        "x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6 \\\\ x_7 \\\\ x_8 \\\\ x_9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "X@W =\n",
        "\\begin{bmatrix}\n",
        "k_1 x_1 + k_2 x_2 + k_3 x_4 + k_4 x_5 \\\\\n",
        "k_1 x_2 + k_2 x_3 + k_3 x_5 + k_4 x_6 \\\\\n",
        "k_1 x_4 + k_2 x_5 + k_3 x_7 + k_4 x_8 \\\\\n",
        "k_1 x_5 + k_2 x_6 + k_3 x_8 + k_4 x_9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Lets explore these differences further. \n",
        "\n",
        "**Repeating Weigths(parameter sharing)-** It is one of the reason behind efficiancy of CNNs, in Dense matrix multiplication input gets multiplied with parameter exactly once to create a output which is not the case in Convolution Neural netwroks the Kernal slide over the input which means that each parameter of the kernal, is used at evey position in input Therefore, rather than learning different parameters for every position we only learn one set of weights. \n",
        "\n",
        "**Weight Matrix filled with zeros(sparse repersentation)-** The size of the kernal is smaller than the size of the input therefor, when we repersent the convolutions in a matrix multiplication operation it results in a matrix which is filled with zeros and one might think that because of all these zeros we might be loosing some features of the input especially in strided convolutions which is not optimal but if we look a the diagram below you can see that is not the case. X being our input and h being a shallow layer and g being a deep layer you can see that deeper layer is connected to almost all of the images features. \n",
        "\n",
        "<img alt=\"diagram for sparse connection taken from Deep Learning book by ian goodfellow\" width=\"774\" caption=\"diagram for sparse connection taken from Deep Learning book by ian goodfellow\" id=\"sparceconnection\" src=\"sparceconectivity.png\">\n",
        "\n",
        "## Understanding the Code \n",
        "\n",
        "So What does it mean when we are writing this code. \n"
      ],
      "id": "4e677a2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conv(1 ,4)"
      ],
      "id": "4be87893",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function will recieve a 28X28 image(ignorning batch_size) with one channel(since its black and white) and output of this layer after using relu will be 4 different activation maps created by 4 different kernals and the size of the activation maps will be of size 14x14(because of the stride=2) and the same happens till the last layer which outputs the probability distribution for each digit from 0-9. We are not using relu in last layer as we are using cross_entropy loss fuction which has its own softmax function and expects raw logits. \n",
        "\n",
        "This layer has 1 input channel, 4 output channels, and a 3×3 kernel therefore, the total parameters of this layer will be:-\n",
        "\n",
        "\n",
        "```{math}\n",
        " 1x4x3x3 = 36 parameters \n",
        "```\n",
        "\n",
        "\n",
        "Confirming our calculations by fetching the parameters of first layer  :-\n",
        "\n",
        "\n",
        "```{code}\n",
        "conv1 = simple_cnn[0][0]\n",
        "conv1.weight\n",
        "```\n",
        "\n",
        "```{code}\n",
        "Parameter containing:\n",
        "tensor([[[[ 0.2922,  0.3600,  0.2967],\n",
        "          [-0.0044,  0.0414, -0.0608],\n",
        "          [ 0.1634, -0.0885,  0.2995]]],\n",
        "\n",
        "\n",
        "        [[[-0.2102,  0.3089, -0.1890],\n",
        "          [-0.1660,  0.1155,  0.3302],\n",
        "          [-0.0576,  0.0286, -0.2662]]],\n",
        "\n",
        "\n",
        "        [[[-0.3527, -0.0673,  0.2557],\n",
        "          [-0.1725, -0.3262, -0.3382],\n",
        "          [-0.1993, -0.3218, -0.5433]]],\n",
        "\n",
        "\n",
        "        [[[ 0.3354,  0.4143,  0.6307],\n",
        "          [ 0.8166,  1.2680,  0.7831],\n",
        "          [ 0.5499,  1.0570,  1.0479]]]], device='cuda:0', requires_grad=True)\n",
        "```\n",
        "\n",
        "\n",
        "as you can see the first layer has 36 parameters just as we calculated. Each 3x3 matrix that you can see in the output is a kernal which containing differents parameters which will slide over our input image. \n",
        "\n",
        "\n",
        "### Refrences\n",
        "\n",
        "Fast.ai Course\n",
        "Howard, J. (n.d.). Lesson 15: Deep learning for coders. Fast.ai. Retrieved March 15, 2025, from https://course.fast.ai/Lessons/lesson15.html\n",
        "\n",
        "Deep Learning Book\n",
        "Goodfellow, I., Bengio, Y., & Courville, A. (2016). Convolutional networks. In Deep learning (pp. 326-366). MIT Press. https://www.deeplearningbook.org/contents/convnets.html\n",
        "\n",
        "Medium Article\n",
        "Basart, J. (2018, July 9). CNNs from different viewpoints. Medium - Impact AI. https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c\n",
        "```"
      ],
      "id": "8c115c5c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/macbook/Library/Python/3.9/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}